<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Harsh Agrawal: Personal Website</title>


    <!-- Bootstrap Core CSS - Uses Bootswatch Flatly Theme: http://bootswatch.com/flatly/ -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/freelancer.css" rel="stylesheet">
    <link href="css/timeline.css" rel="stylesheet">
   
    <!-- Custom Fonts -->
    <link href="http://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

    <script src="js/modernizr.js"></script>
    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top" class="index">

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-about-me-hidden navbar-brand" href="#page-top">Harsh Agrawal</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li class="page-scroll">
                        <a href="#timeline">Timeline</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#about">Publications</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#projects">Projects</a>
                    </li>
                    <li>
                        <a href="https://drive.google.com/open?id=1UzyjfWd0-lx62uz1L4xcwGVD7ZGTJK99">CV</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->

        </div>
        <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
        <div class="container">
            <div class="row">

                <div class="col-xs-4">
                    <img class="img-responsive img-circle" src="img/dp1.jpg" alt="">
                </div>
                <div class="col-xs-8">
                    <div class="intro-text">
                        <span class="name">Harsh Agrawal</span>
                        <br>

                        <span class="about_me"><p style="text-align: justify">
                            I am a first year Ph.D student at Georgia Tech advised by <a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>. I also closely collaborate with <a href="https://www.cc.gatech.edu/~parikh/">Devi Parikh</a> and <a href="http://alexander-schwing.de">Alexander Schwing</a>. 
                            My research lies at the intersection of computer vision and natural language processing.
                            In my free time, I also help maintain and manage an AI hosting platform called <a href="https://evalai.cloudcv.org">EvalAI</a> (part of <a href="https://cloudcv.org">CloudCV</a> project) which aims to make AI research more reproducible. Before this, I spent a
                            couple of years as a Research Engineer at Snap Research where I was responsible for building large-scale infrastructure for visual recognition,
                            search and developed algorithms for low-shot instance detection. 
                        </p>
                        </span>
                        <hr>
                        <span class="skills"> <ul class="list-inline">
                            <li>
                                <a href="https://scholar.google.com/citations?user=0nsfDPAAAAAJ&hl=en" class="btn-social btn-outline"><i class="ai ai-google-scholar"></i></a>
                            </li>
                            <li>
                                <a href="https://www.linkedin.com/in/harsh092" class="btn-social btn-outline"><i class="fa fa-fw fa-linkedin"></i></a>
                            </li>
                            <li>
                                <a href="https://github.com/dexter1691" class="btn-social btn-outline"><i class="fa fa-fw fa-github"></i></a>
                            </li>
                            <li>
                                <a href="https://twitter.com/harsh_092" class="btn-social btn-outline"><i class="fa fa-fw fa-twitter"></i></a>
                            </li>
                        </ul></span>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <section id="news-list">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>News</h2>
                    <hr class="star-light">
                </div>
            </div>
            <div class="row">
            <div class="col-lg-12">
                <ul class="news-list">
                    <li><p><span class="news-date">Jan 2019</span> Awarded the  <a href="https://snapresearchfs.splashthat.com"> Snap Fellowship!</a></p></li>
                    <li><p><span class="news-date">Jan 2019</span> Spending the Spring semester at UIUC working with  <a href="http://alexander-schwing.de"> Alex Schwing</a></p></li>
                    <li><p><span class="news-date">Aug 2018</span> Starting PhD at Georgia Tech under  <a href="https://www.cc.gatech.edu/~dbatra/"> Dhruv Batra</a></p></li>
                </ul>
            </div>
        </div>  
        </div>
    </section>

    <section id="timeline">
        <div class="container" >
            <div class="row" style="margin-bottom: 10%">
                <div class="col-lg-12 text-center">
                    <h2>Timeline</h2>
                    <hr class="star-light">
                </div>
            </div>
            <div class="row">
                <section id="cd-timeline" class="cd-container">
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/graduation_cap_512.png" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>PhD Student</h2>
                            <span>August, 2018</span>
                            <p>Georgia Tech</p>
                            <p>Advisor: Dr. Dhruv Batra</p>

                        </div> <!-- cd-timeline-content -->
                    </div> <!-- cd-timeline-block -->

                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/Briefcase-15.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Research Engineer</h2>
                            <span>July, 2016</span>
                            <p> Snapchat Research. </p>
                            <p> Inventing the next generation of creative tools to “empower people to express themselves, live in the moment, learn about the world, and have fun together.”</p>

                        </div> <!-- cd-timeline-content -->
                    </div> <!-- cd-timeline-block -->
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/graduation_cap_512.png" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>M.S in Computer Engineering</h2>
                            <span>May, 2016</span>
                            <p> Machine Learning and Perception Lab, Virginia Tech. </p>
                            <p> Advisor: Dr. Dhruv Batra</p>
                            <p> Worked on problems at the intersection of computer vision, natural language and machine learning.</p>

                        </div> <!-- cd-timeline-content -->
                    </div> <!-- cd-timeline-block -->
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/code.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Organization Administrator for CloudCV</h2>
                            <span>2015 - 2018</span>
                            <p> Google Summer of Code (GSOC), '15 - '18 </p>
                            <p> Mentored 4 generations GSOC students on various projects under the CloudCV organization.</p>

                        </div>
                    </div>
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/Briefcase-15.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Software Engineer Intern</h2>
                            <span>June - August, 2015</span>
                            <p> Microsoft Dynamics </p>
                            <p> Worked on applying machine learning techniques to automate work-flows for sales lifecycle in Microsoft Dynamics CRM </p>
                        </div>
                    </div>
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/graduation_cap_512.png" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>B. Tech in Computer Engineering</h2>
                            <span>June, 2014</span>
                            <p> Graduated from Delhi College of Engineering </p>
                            <p> Worked on applications of computer vision for an Unmanned Aerial Vehicle.</p>
                        </div>
                    </div>
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/light-bulb-3.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Visiting Student</h2>
                            <span>June, 2014</span>
                            <p> Machine Learning and Perception Lab, Virginia Tech </p>
                            <p> Advisor: Dr. Dhruv Batra</p>
                            <p> Worked on building the first prototype of CloudCV.</p>
                        </div>
                    </div>

                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/light-bulb-3.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Visiting Student Researcher</h2>
                            <span>September, 2012</span>
                            <p> Mobile and Ubiquitous Computing, IIIT-Delhi </p>
                            <p> Developed  a cloud enabled cell broadcast service based localization algorithms for
                                Android smartphones. Also designed and implemented an algorithm to build mobility profiles for predicting
                                encounters between mobile phone users allowing them to share content locally through
                                bluetooth.
                            </p>
                        </div>
                    </div>
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/camera_2.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Computer Vision Lead</h2>
                            <span>September, 2010</span>
                            <p> Unmanned Aerial Systems - Delhi Technological University </p>
                            <p> Performed autonomous extraction and segmentation of objects from aerial imagery in natural scenes for Student UAS Competition.
                                Developed a robust, user-friendly GUI on Qt to control camera properties and process the imagery feed acquired wirelessly.</p>

                        </div>
                    </div>
                </section> <!-- cd-timeline -->
            </div>

        </div>
    </section>


    <!-- About Section -->
    <section class="success" id="about">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Publications</h2>
                    <hr class="star-light">
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col-sm-3 hidden-xs">
                    <img class="img-responsive" src="img/SortStory.jpg" style="width: 180px;" alt="">
                </div>
                <div class="col-sm-8">
                    <h4 class="pubt">Sort Story: Sorting Jumbled Images and Captions into Stories</h4>
                    <p class="pubd">
                        Temporal common sense has applications in AI tasks such as QA, multi-document summarization, and human-AI communication.
                        We propose the task of sequencing -- given a jumbled set of aligned image-caption pairs that belong to a story, the task is
                        to sort them such that the output sequence forms a coherent story. We present multiple approaches, via unary (position) and
                        pairwise (order) predictions, and their ensemble-based combinations, achieving strong results on this task. As features, we
                        use both text-based and image-based features, which depict complementary improvements. Using qualitative examples, we
                        demonstrate that our models have learnt interesting aspects of temporal common sense.
                    </p>
                    <h4 class="puba">Harsh Agrawal<sup>*</sup>, Arjun Chandrasekaran<sup>*</sup>, Dhruv Batra, Devi Parikh, Mohit Bansal</h4>
                    <div class="pubv">EMNLP 2016</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://arxiv.org/abs/1606.07493">PDF</a></li>
                            <li><a href="https://www.youtube.com/watch?v=CMRy4Y-ZwGE">AI Guild Podcast #2</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-3 hidden-xs">
                    <img class="img-responsive" src="img/HumanAttention.jpg" style="width: 180px;" alt="">
                </div>
                <div class="col-sm-8">
                    <h4 class="pubt">Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions?</h4>
                    <p class="pubd">We conduct large-scale studies on `human attention' in Visual Question Answering (VQA) to understand where humans
                        choose to look to answer questions about images. We design and test multiple game-inspired novel attention-annotation interfaces
                        that require the subject to sharpen regions of a blurred image to answer a question. Thus, we introduce the
                        VQA-HAT (Human ATtention) dataset. We evaluate attention maps generated by state-of-the-art VQA models against human attention
                        both qualitatively (via visualizations) and quantitatively (via rank-order correlation). Overall, our experiments show that
                        current attention models in VQA do not seem to be looking at the same regions as humans.
                    </p>
                    <h4 class="puba">Abhishek Das<sup>*</sup>, Harsh Agrawal<sup>*</sup>, C. Lawrence Zitnick, Devi Parikh, Dhruv Batra</h4>
                    <div class="pubv">CVIU 2017, EMNLP 2016, ICML 2016 Workshop on Visualization for Deep Learning (Best Student Paper)</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://arxiv.org/abs/1606.03556">PDF</a></li>
                            <li><a href="https://www.theverge.com/2016/7/12/12158238/first-click-deep-learning-algorithmic-black-boxes">The Verge</a></li>
                            <li><a href="https://nautil.us/issue/40/learning/is-artificial-intelligence-permanently-inscrutable">Nautilus</a></li>
                            <li><a href="https://www.newscientist.com/article/2095616-robot-eyes-and-humans-fix-on-different-things-to-decode-a-scene/">New Scientist</a></li>
                            <li><a href="https://www.technologyreview.com/s/601819/ai-is-learning-to-see-the-world-but-not-the-way-humans-do/">TechRadar</a></li>
                            <li><a href="https://www.techradar.com/news/world-of-tech/robots-and-humans-see-the-world-differently-but-we-don-t-know-why-1324165">MIT Tech Review</a></li>

                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-3 hidden-xs">
                    <img class="img-responsive" src="img/ObjProposals.jpg" style="width: 180px;">
                </div>
                <div class="col-sm-8">
                    <h4 class="pubt">Object-Proposal Evaluation Protocol is 'Gameable'</h4>
                    <p class="pubd">Object proposals have quickly become the de-facto pre-processing step in a number of vision
                        pipelines (for object detection, object discovery, and other tasks). Their performance is
                        usually evaluated on partially annotated datasets. In this paper, we argue that the choice
                        of using a partially annotated dataset for evaluation of object proposals is problematic -- as
                        we demonstrate via a thought experiment, the evaluation protocol is 'gameable', in the sense
                        that progress under this protocol does not necessarily correspond to a "better" category
                        independent object proposal algorithm.
                    </p>
                    <h4 class="puba">Neelima Chavali<sup>*</sup>, Harsh Agrawal<sup>*</sup>, Aroma Mahendru<sup>*</sup>, Dhruv Batra</h4>
                    <div class="pubv">CVPR 2016 (Spotlight)</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://filebox.ece.vt.edu/~aroma/web/object-proposals.html">Project</a></li>
                            <li><a href="https://arxiv.org/abs/1505.05836">PDF</a></li>
                            <li><a href="https://github.com/Cloud-CV/object-proposals">Github</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-3 hidden-xs">
                    <img class="img-responsive" src="http://cloudcv.org/static/img/Page-1.jpg" style="width: 180px;" alt="">
                </div>
                <div class="col-sm-8">
                    <h4 class="pubt">CloudCV: Large Scale Distributed Computer Vision as a Cloud Service</h4>
                    <p class="pubd">
                        We are witnessing a proliferation of massive visual data. Unfortunately scaling existing
                        computer vision algorithms to large datasets leaves researchers repeatedly solving the same
                        algorithmic, logistical, and infrastructural problems. Our goal is to democratize computer
                        vision; one should not have to be a computer vision, big data and distributed computing expert
                        to have access to state-of-the-art distributed computer vision algorithms. We present CloudCV,
                        a comprehensive system to provide access to state-of-the-art distributed computer vision
                        algorithms as a cloud service through a Web Interface and APIs.
                    </p>
                    <h4 class="puba">Harsh Agrawal, Clint Solomon Mathialagan, Yash Goyal, Neelima Chavali, Prakriti Banik, Akrit Mohapatra, Ahmed Osman, Dhruv Batra</h4>
                    <div class="pubv">Book Chapter: Mobile Cloud Visual Media Computing, 265-290</div>
                    <div class="publ">
                        <ul>
                            <li><a href="http://cloudcv.org">Project</a></li>
                            <li><a href="https://http://arxiv.org/abs/1506.04130">PDF</a></li>
                            <li><a href="https://github.com/Cloud-CV">Github</a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>

    

            
    <!-- Portfolio Grid Section -->
    <section id="projects">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Projects</h2>
                    <hr class="star-light">
                </div>
            </div>
            <div class="band">
                <div class="item-1">
                  <a href="#EvalAI" class="card portfolio-link" data-toggle="modal">
                    <div class="thumb" style="background-image: url(https://raw.githubusercontent.com/Cloud-CV/EvalAI/master/docs/source/_static/img/evalai_logo.png);"></div>
                    <article class="article">
                      <h1>EvalAI</h1>
                      <span>Georgia Tech</span>
                    </article>
                  </a>
                </div>
                <div class="item-2">
                  <a href="#Fabrik" class="card portfolio-link">
                    <div class="thumb" style="background-image: url(img/Fabrik.png);"></div>
                    <article class="article">
                      <h1>Fabrik</h1>
                      <span>Georgia Tech</span>
                    </article>
                  </a>
                </div>
                <div class="item-3">
                  <a href="#Origami" class="card portfolio-link" data-toggle="modal">
                    <div class="thumb" style="background-image: url(img/Origami.jpg);"></div>
                    <article class="article">
                      <h1>Origami</h1>
                      <span>Georgia Tech</span>
                    </article>
                  </a>
                </div>
                <div class="item-4">
                  <a href="#CloudCV" class="card portfolio-link" data-toggle="modal">
                    <div class="thumb" style="background-image: url(img/cloudcv.png);"></div>
                    <article class="article">
                      <h1>CloudCV</h1>
                      <span>Georgia Tech</span>
                    </article>
                  </a>
                </div>
                <div class="item-5">
                  <a href="#Garuda" class="card portfolio-link" data-toggle="modal">
                    <div class="thumb" style="background-image: url(img/garuda.jpg)"></div>
                    <article class="article">
                      <h1>Garuda</h1>
                      <span>UAS-DTU</span>
                    </article>
                  </a>
                </div>
                <div class="item-6">
                  <a href="#Aarush" class="card portfolio-link" data-toggle="modal">
                    <div class="thumb" style="background-image: url(img/Arush_X1.JPG);"></div>
                    <article class="article">
                      <h1>Aarush X-1</h1>
                      <span>UAS-DTU</span>
                    </article>
                  </a>
                </div>
                <div class="item-7">
                  <a href="#AMTChat" class="card portfolio-link" data-toggle="modal">
                    <div class="thumb" style="background-image: url(img/amtchat.png);"></div>
                    <article class="article">
                      <h1>AMT Chat Interface</h1>
                      <span>Virginia Tech</span>
                    </article>
                  </a>
                </div>
                <div class="item-8">
                    <a href="#NoteWorthy" class="card portfolio-link" data-toggle="modal">
                      <div class="thumb" style="background-image: url(img/noteworthy3.png);"></div>
                      <article class="article">
                        <h1>Noteworthy</h1>
                        <span>M Hacks</span>
                      </article>
                    </a>
                </div>
                <div class="item-9">
                    <a href="#Mobishare" class="card portfolio-link" data-toggle="modal">
                      <div class="thumb" style="background-image: url(img/mobishare.png);"></div>
                      <article class="article">
                        <h1>Mobishare</h1>
                        <span>IIIT-D</span>
                      </article>
                    </a>
                </div>
        
                <div class="item-10">
                    <a href="#Trippr" class="card portfolio-link" data-toggle="modal">
                      <div class="thumb" style="background-image: url(img/trippr.png);"></div>
                      <article class="article">
                        <h1>Trippr</h1>
                        <span>AngelHack</span>
                      </article>
                    </a>
                  </div>
                
        
              </div>
        </div>
    </section>
    

    <!-- Footer 
        <footer class="text-center">
            <div class="footer-below">
                <div class="container">
                    <div class="row">
                        <div class="col-lg-12">
                            Copyright &copy; Harsh Agrawal 2016
                        </div>
                    </div>
                </div>
            </div>
        </footer>
    -->

    <!-- Scroll to Top Button (Only visible on small and extra-small screen sizes) -->
    <div class="scroll-top page-scroll visible-xs visible-sm">
        <a class="btn btn-primary" href="#page-top">
            <i class="fa fa-chevron-up"></i>
        </a>
    </div>

    <!-- Portfolio Modals -->
    <div class="portfolio-modal modal fade" id="CloudCV" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-xs-12">
                        <div class="modal-body">
                            <h2>CloudCV</h2>
                            <br>
                            <img src="img/cloudcv_banner.png" class="img-responsive img-centered" alt="">
                         
                            <p> CloudCV began in the summer of 2013 as a research project within the Machine Learning and Perception lab at Virginia Tech (now at Georgia Tech), with the ambitious goal of making platforms to make AI research more reproducible. We’re a young community working towards enabling developers, researchers, and fellow students to build, compare and share state-of-the-art Artificial Intelligence algorithms. We believe that one shouldn’t have to be an AI expert to have access to cutting edge vision algorithms. Likewise, researchers shouldn’t have to worry about building a service around their deep learning models to showcase and share it with others. </p>

                            <p> We have participated in the past three installments of Google Summer of Code (2015-2017), over the course of which our students built several excellent tools and features.
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="http://cloudcv.org">Website</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://github.com/Cloud-CV">Github</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://summerofcode.withgoogle.com/organizations/5746858777378816/">GSOC</a>
                                    </strong>
                                </li>
                            </ul>
                            
                            <div class="row">
                                <div class="col-xs-6">
                                    <h3> Python APIs in action</h3>
                                    <img class="img-responsive" src="https://raw.githubusercontent.com/Cloud-CV/py-cloudcv/b3bb1a362fbd2f3a250419a078d3987db90ff0d7/python_screenshot.gif">
                                </div>
                                <div class="col-xs-6">
                                    <h3> Matlab APIs in action</h3>
                                    <img class="img-responsive" src="https://raw.githubusercontent.com/Cloud-CV/mat-cloudcv/master/matlab_screenshot.gif">

                                </div>
                            </div>

                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Aarush" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Aarush X-1</h2>
                            <br>
                            <img src="img/Arush_X1.JPG" class="img-responsive img-centered" alt="">
                            <p>Aarush is a prototype of the UAV developed with financial resources and engineering mentoring support
                                from Lockheed Martin Corporation. Traffic Management, Geomatics, Mining Surveillance, Border patrol
                                are just some of the areas in which this UAV can be put to effective, efficient use. </p>
                            <br>
                            <h3> Teaser Video </h3>
                            <br>
                            <iframe src="https://www.youtube.com/embed/BL-Rbf3iEKI" frameborder="0" allowfullscreen style="position: relative; height: 750px; width: 100%;"></iframe>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Origami" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Origami</h2>
                            <br>
                            <img src="img/origami_banner.png" class="img-responsive img-centered" alt="">
                            <p>Origami (previously called CloudCV-fy your code) is a AI-as-a-service solution that allows researchers to easily convert their deep learning models into an online service that is widely accessible to everyone without the need to setup the infrastructure, resolve the dependencies, and build a web service around the deep learning model. By lowering the barrier to entry to latest AI algorithms, we provide developers, researchers and students the ability to access any model using a simple REST API call.</p>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="http://origami.cloudcv.org">Website</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://github.com/Cloud-CV/Origami">Github</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://gitter.im/Cloud-CV/Origami">Gitter Channel</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="EvalAI" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>EvalAI</h2>
                            <br>
                            <img src="img/evalai_logo.png" class="img-responsive img-centered" alt="">
                            <h3> The Problem: Benchmarking progress in AI is hard </h3>

                            <p>
                                Artificial Intelligence (AI) as a field has progressed significantly in the recent years. A major portion of this progress can be attributed to the proposal of bold new multi-modal AI tasks (recognition, captioning, VQA, Visual Dialog) together with curation of associated datasets -- Common Objects in COntext (COCO), ImageNet, Visual Question Answering (VQA), Stanford Question Answering Dataset (SQUAD), etc. Moving forward, with more datasets being released and new tasks being proposed, comparing a new algorithm with existing algorithms is nontrivial and is hindered by multiple factors:
                            
                                <ol class="list item-details">
                                    <li>Different evaluation schemes for the same task.</li>
                                    <li>Implementation of the different metric or evaluation across different splits of the dataset.</li>
                                    <li>Computational bottlenecks on evaluation servers holding unseen test data.</li>
                                </ol>
                            </p>
                            
                            <h3>The Solution: EvalAI</h3>
                            <p>
                                EvalAI is an open source web platform that aims to help researchers, students and data scientists create, collaborate, and participate in AI challenges. By simplifying and standardizing the process of benchmarking AI, we want to circumvent many of the factors impeding the rate of progress in AI. Our plan is to do this in the following ways: 
                            
                                <ol class="list item-details">
                                    <li>Reduced barrier to entry for hosting AI challenges.</li>
                                    <li>Standardized evaluation protocols (same dataset splits and metrics) for measuring the performance of different algorithms on a given task.<br></li>
                                    <li>Central public leaderboards (“who is the best on X?”).</li>
                                    <li>Faster evaluation of submissions using parallelization techniques that take advantage of distributed multi-core machines.</li>
                                </ol>
                            </p>

                            <h3> Important links: </h3>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="https://evalai.cloudcv.org">Website</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://github.com/Cloud-CV/EvalAI">Github</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://evalai.readthedocs.io/en/latest/">Documentation</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://gitter.im/Cloud-CV/EvalAI">Gitter Link</a>
                                    </strong>
                                </li>
                            </ul>
                    
                            <h3> How it is different from Kaggle? </h3>
                            <p>
                                The central differences are:
                            
                            <ul class="list item-details">
                                <li> Custom Evaluation Protocols and Phases: We have designed versatile backend framework that can support user-defined evaluation metrics, various evaluation phases, private and public leaderboard. </li>
                                <li> Faster Evaluation: The backend evaluation pipeline is engineered so that submissions can be evaluated parallelly using multiple cores on multiple machines via mapreduce frameworks offering a significant performance boost over similar web AI-challenge platforms.</li>
                                <li>Portability: Since the platform is open-source, users have the freedom to host challenges on their own private servers rather than having to explicitly depend on Cloud Services such as AWS, Azure, etc.</li>
                                <li>Centralized Leaderboard: Challenge Organizers whether host their challenge on EvalAI or forked version of EvalAI, they can send the results to main EvalAI server. This helps to build a centralized platform to keep track of different challenges.</li>
                                
                            </ul>
                            </p>
                            

                            <h3> Performance comparisons with other platforms: </h3>

                            <p> EvalAI hosted Visual Question Answering (VQA) 2017 challenge as its first challenge. To give some background, last year, the VQA 2016 challenge was hosted on Codalab, and on average evaluation would take ~10 minutes. This year, the dataset for the VQA Challenge 2017 was twice as large. Despite this, we have found that our parallelized backend took only ~130 seconds to evaluate on the whole test set of VQA dataset. </p>

                            <h3> Research Organizations using EvalAI: </h3>
                            
                            <div class="row">
                            <div class="col-xs-3"><img src="https://evalai.cloudcv.org/dist/images/organizations/fb.png" class="img-responsive img-centered" alt=""></div>
                            <div class="col-xs-3"><img src="https://evalai.cloudcv.org/dist/images/organizations/google.png" class="img-responsive img-centered" alt=""></div>
                            <div class="col-xs-3"><img src="https://evalai.cloudcv.org/dist/images/organizations/mapillary.png" class="img-responsive img-centered" alt=""></div>
                            <div class="col-xs-3"><img src="https://evalai.cloudcv.org/dist/images/organizations/gt.png" class="img-responsive img-centered" alt=""></div>
                            </div>
                            
                            <br>
                            <br>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Fabrik" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Fabrik</h2>
                            <br>
                            <img src="https://github.com/Cloud-CV/Fabrik/raw/master/example/fabrik_demo.gif?raw=true" class="img-responsive img-centered" alt="">
                            <p> Fabrik is an online collaborative platform to build, visualize and train deep learning models via a simple drag-and-drop interface. It allows researchers to collaboratively develop and debug models using a web GUI that supports importing, editing and exporting networks written in widely popular frameworks like Caffe, Keras, and TensorFlow.</p>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="http://fabrik.cloudcv.org">Website</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://github.com/Cloud-CV/Fabrik">Github</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://gitter.im/Cloud-CV/IDE">Gitter Channel</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Garuda" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Garuda</h2>
                            <br>
                            <img src="img/garuda.jpg" class="img-responsive img-centered" alt="">
                            <p>GARUDA, a modified Sig Rascal 110 R/C aircraft along with its Ground Control System is capable of performing
                                autonomous flight & navigation, simultaneously gathering actionable surveillance data using optical sensors.
                                The system includes commercially available autopilot system, Piccolo II for control & navigation with a customized
                                imagery system capable of capturing & transmitting high definition images of the hostile territory simultaneously
                                processing it to deliver actionable intelligence. The Ground Control Station (GCS) and the aircraft communicate
                                in real time to provide situational awareness and safe and reliable flight. Due to it's modular design, the entire system
                                can be brought to a flying state in less than 20 minutes. We participated with this system in Student Unmanned Aerial Systems (SUAS) 2012 competition and secured 3rd position.</p>
                            
                            <p> Garuda was developed as part of the Unmanned Aerial Systems - Delhi Technological University (UAS-DTU) project. UAS-DTU is a team of undergraduate students of Delhi Technological University, devoted to developing indigenous technological solutions for UAVs. Our ultimate goal was to reduce India's reliance on off-the-shelf products and foreign UAVs. Focussing on humanitarian uses of UAVs, we are developing a new generation of low-cost Image Processing and Flight Control Systems to aid in Surveillance and Reconnaissance.</p>

                            <p>The team, under mentorship and funding from Lockheed Martin, is the first to develop a Next Generation Urban UAS - Aarush X1, that is tailor- made for surveillance in urban jungles like Delhi and Mumbai. The team signed its first MoU with Lockheed Martin in 2009. The second MoU was signed in 2013, under which a new version of Aarush (Aarush X2) is being developed. The team annually participates in AUVSIs SUAS competition, which stands for Student Unmanned Aerial Systems competition. The competition is held in Maryland, USA where more than 30 universities come every year with their UAVs hoping to win the competition. We are the first team from India to participate in this competition (Our first participation was in 2009), and also the first team from India to achieve a podium finish (We were ranked 3rd in 2012). In 2013, the team ranked 6th. After these years of experience through the competition and Lockheed Martin project, we are now capable of manufacturing Unmanned Aerial Systems for the market with the capabilities of Aerial Imagery, and GCS Softwares for the processing of these images.</p>
                            <br>
                            <h3>Video: Journey of UAS-DTU</h3>
                            <br>
                            <iframe src="https://www.facebook.com/video/embed?video_id=10151167933007739" width="560" height="315" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowTransparency="true" allowFullScreen="true"></iframe>
                            <br>
                            <h3>Important Links</h3>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="img/journal_2012.pdf">Journal Paper</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="http://www.thehindu.com/todays-paper/tp-features/tp-educationplus/laurels-for-team-uasdtu/article3796999.ece">Article in The Hindu</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="AMTChat" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>AMT Chat Interface</h2>
                            <br>
                            <img src="img/amtchat.png" class="img-responsive img-centered" alt="">
                            <p>Source for the two-person chat interface used to collect the VisDial dataset on Amazon Mechanical Turk. A demo is available <href src="https://godel.ece.vt.edu/visdial_chat/">here</href> (open in two separate tabs to be paired for conversation).</p>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="https://github.com/batra-mlp-lab/visdial-amt-chat">Github</a>
                                    </strong>
                                </li>

                            </ul>
                            <h3> How things works </h3>
                            <p>
                                The real-time chat interface is built using Node.js and Socket.io. We use Redis to maintain a pool of images for live HITs and all data finally resides in a MySQL database.
                                <br><br>
                                A database table stores images from the COCO dataset each with a randomly picked caption. A batch of images from this table are then pushed to a Redis list for launching HITs. The web server corresponding to the chat interface pairs two AMT workers, assigns them roles (questioner or answerer) and shows corresponding interface, picks an image from the Redis list to collect data on and saves their conversation in the database, also marking that image as 'complete' once the HIT is done. This happens in parallel so workers aren't left waiting, and the server ensures workers have unique ids. Disconnects are handled gracefully — remaining worker is asked to continue asking questions or providing facts (captions) up to 10 messages. Once the HITs are complete, scripts in mturk_scripts/approve can be used to review, approve, reject HITs and pay workers.

                            </p>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="NoteWorthy" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>NoteWorthy</h2>
                            <br>
                            <div class="row">
                                <div class="col-xs-3 col-md-3">
                                    <img src="img/noteworthy1.png" class="img-responsive img-centered" alt=""></div>
                                <div class="col-xs-3 col-md-3">
                                    <img src="img/noteworthy2.png" class="img-responsive img-centered" alt="" ></div>
                                <div class="col-xs-3 col-md-3">
                                    <img src="img/noteworthy3.png" class="img-responsive img-centered" alt=""></div>
                                <div class="col-xs-3 col-md-3">
                                    <img src="img/noteworthy4.png" class="img-responsive img-centered" alt=""></div>
                            </div>
                            <div class="row">
                            <p>What if you could replace the slow and monotone professor with complete and efficient notes? Rather than begging for them from the smartest students in class, Noteworthy provides a smart alternative ecosystem of notes. Whether you've simply wanted to skip a class without the academic problems, or you wanted to reinforce your education, Noteworthy gives you the greatest studying experience. Noteworthy, an app founded at MHacks, allows for easy and seamless digitization of notes. Noteworthy takes the noteworthiest notes from across the world, and brings them to you anywhere. With course, professor, and date choices, students can find the right notes for the right class on the right day. Noteworthy will save you time and get you better results for your education.</p>

                            <p>Noteworthy was developed while participating in MHacks 2014 - one of the biggest 48 hour hackathon competition orgamized by University of Michigan, Ann Arbor</p>
                            </div>

                            
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Trippr" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>Trippr</h2>
                            <br>
                            
                            <p> Trippr is a collaborative trip planning app powered by IBM Watson based personal assistant. This app was developed while participating 
                            in Angel Hacks, Seattle - a 24 hour hackathon in the summer of 2013. It consisted of a combination of Android app, Pebble Smartwatch app and a Web app through which
                            people can chat online with their friends, ask questions to a smart personal assistant and book iteneraries. </p>

                            <p> The personal assistant powered by IBM Watson can hold conversation with the group of users to suggest popular destinations, restaurants, cheapest flights. It also automatically built an itenerary based on users choices. This app provided smart features similar to Google Trips.</p>

                            <p> Our app also won the "Best use of Respoke API" award.</p>
                            
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Mobishare" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Mobishare</h2>
                            <br>
                            <img src="img/MSR_TechV2013.jpg" class="img-responsive img-centered" alt="">
                            <p>
                                
                            </p>
                            
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="js/classie.js"></script>
    <script src="js/cbpAnimatedHeader.js"></script>

    <script src="js/timeline.js"></script>
    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/freelancer.js"></script>
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-92670333-1', 'auto');
        ga('send', 'pageview');

    </script>
</body>

</html>
