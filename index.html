<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Harsh Agrawal: Personal Website</title>


    <!-- Bootstrap Core CSS - Uses Bootswatch Flatly Theme: http://bootswatch.com/flatly/ -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/timeline.css" rel="stylesheet">
    <link href="css/freelancer.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700,800&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet"
        type="text/css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&display=swap" rel="stylesheet">
    <script src="js/modernizr.js"></script>
    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top" class="index">

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse"
                    data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-about-me-hidden navbar-brand" href="#page-top">Harsh Agrawal</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <!-- <li class="page-scroll">
                            <a href="#timeline">Timeline</a>
                        </li> -->
                    <li class="page-scroll">
                        <a href="#about">Publications</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#projects">Projects</a>
                    </li>
                    <li>
                        <a href="https://drive.google.com/open?id=1UzyjfWd0-lx62uz1L4xcwGVD7ZGTJK99">CV</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->

        </div>
        <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
        <div class="container">
            <div class="row">

                <div class="col-xs-4">
                    <img class="img-responsive img-circle" src="img/DP.jpg" alt="">
                </div>
                <div class="col-xs-8">
                    <div class="intro-text">
                        <span class="name">Harsh Agrawal</span>
                        <br>

                        <span class="about_me">
                            <p style="text-align: justify">
                                I am a fourth year Ph.D student at Georgia Tech advised by <a
                                    href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>. I also closely
                                collaborate with <a href="https://www.cc.gatech.edu/~parikh/">Devi Parikh</a> and <a
                                    href="http://alexander-schwing.de">Alexander Schwing</a>.
                                My research lies at the intersection of computer vision and natural language processing with a focus on visio-linguistic understanding for Embodied AI. 
                                During my PhD, I have been fortunate to intern at Facebook AI Research (2019) with <a href="https://research.fb.com/people/rohrbach-marcus/">Marcus Rohrbach</a>, at NVIDIA (2020)
                                with <a href="https://research.nvidia.com/person/gal-chechik">Gal Chechik</a> and at Google (2021) with <a href="https://panderson.me/">Peter Anderson</a>. 
                            </p>
                            <p style="text-align: justify">
                                In my free time, I also help maintain and manage an AI challenge hosting platform called <a
                                    href="https://evalai.cloudcv.org">EvalAI</a> (part of <a
                                    href="https://cloudcv.org">CloudCV</a> project) which aims to make AI research more
                                reproducible. EvalAI hosts 150+ challenges and has 300+ contributors, 2M+ annual pageviews, 1400+ forks, 4500+ solved issues and merged pull requests, 3000+ ‘stars’ on Github, and financial/equipment support from Google, NVIDIA, and Amazon.
                                Before this, I spent a
                                couple of years as a Research Engineer at Snap Research where I was responsible for
                                building large-scale infrastructure for visual recognition,
                                search and developed algorithms for low-shot instance detection.
                            </p>
                            <p>
                                <b>You can reach me at hagrawal9 at gatech dot edu</b>
                            </p>
                        </span>
                        <hr>
                        <span class="skills">
                            <ul class="list-inline">
                                <li>
                                    <a href="https://www.semanticscholar.org/author/Harsh-Agrawal/37825612?sort=pub-date" class="btn-social btn-outline"><i class="ai ai-semantic-scholar"></i></a>
                                </li>
                                <li>
                                    <a href="https://scholar.google.com/citations?user=0nsfDPAAAAAJ&hl=en"
                                        class="btn-social btn-outline"><i class="ai ai-google-scholar"></i></a>
                                </li>
                                <li>
                                    <a href="https://www.linkedin.com/in/harsh092" class="btn-social btn-outline"><i
                                            class="fa fa-fw fa-linkedin"></i></a>
                                </li>
                                <li>
                                    <a href="https://github.com/dexter1691" class="btn-social btn-outline"><i
                                            class="fa fa-fw fa-github"></i></a>
                                </li>
                                <li>
                                    <a href="https://twitter.com/harsh_092" class="btn-social btn-outline"><i
                                            class="fa fa-fw fa-twitter"></i></a>
                                </li>
                            </ul>
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <section id="affilition">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Affiliations</h2>
                    <hr class="light">
                </div>
            </div>
            <ul class="affiliation-list row">
                <li class="col-sm-3 col-xs-6">
                    <a class="btn-affl">
                        <img class="affilition logo" src="img/google_ai_logo.png">
                    </a><br>
                    Google<br>
                    (Summer 2021)
                </li>
                <li class="col-sm-3 col-xs-6">
                    <a class="btn-affl">
                        <img class="affilition logo" src="img/nvidia_logo.jpeg">
                    </a><br>
                    NVIDIA<br>
                    (Summer 2020)
                </li>
                <li class="col-sm-3 col-xs-6">
                    <a class="btn-affl">
                        <img class="affilition logo" src="img/fb_ai_logo.png">
                    </a><br>
                    Facebook AI Research<br>
                    (Summer 2019)
                </li>
                <li class="col-sm-3 col-xs-6">
                    <a
                        class="btn-affl"><img class="affilition logo" src="img/gt_logo.png"></a><br>
                    Georgia Tech<br>
                    (2018 - Present)
                </li>
                <li class="col-sm-3 col-xs-6">
                    <a class="btn-affl">
                        <img class="affilition logo" src="img/snap_logo.png"></a><br>
                    Snap Research<br>
                    (2016 - 2018)
                </li>
                <li class="col-sm-3 col-xs-6">
                    <a class="btn-affl">
                        <img class="affilition logo" src="img/ms_logo.png">
                    </a><br>
                    Microsoft<br>
                    (Summer 2015)<br>
                </li>
                <li class="col-sm-3 col-xs-6">
                    <a class="btn-affl">
                        <img class="affilition logo" src="img/vt_logo.png">
                    </a><br>
                    Virginia Tech<br>
                    (2014 - 2016)
                </li>
                <li class="col-sm-3 col-xs-6">
                    <a class="btn-affl">
                        <img class="affilition logo" src="img/dtu_logo.jpeg">
                    </a><br>
                    Delhi Technological University<br>
                    (2010- 2014)
                </li>
            </ul>
        </div>
    </section>
    <section id="news-list">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>News</h2>
                    <hr class="light">
                </div>
                <div class="row">
                    <div class="col-xs-4 news-date">Sep 2021</div>
                    <div class="col-xs-8">One paper accepted in NeurIPS 2021!</div>
                </div>
                <div class="row">
                    <div class="col-xs-4 news-date">Jul 2021</div>
                    <div class="col-xs-8">Two papers accepted in ICCV 2021!</div>
                </div>
                <div class="row">
                    <div class="col-xs-4 news-date">May 2021</div>
                    <div class="col-xs-8">One paper accepted in UAI 2021!</div>
                </div>
                <div class="row">
                    <div class="col-xs-4 news-date">Jul 2020</div>
                    <div class="col-xs-8">One paper accepted in ECCV 2020!</div>
                </div>
                <div class="row">
                    <div class="col-xs-4 news-date">Jun 2020</div>
                    <div class="col-xs-8">We were runner-up in the <a href="https://textvqa.org/">TextVQA</a> Challenge
                        2020. </div>
                </div>
                <div class="row">
                    <div class="col-xs-4 news-date">Dec 2019</div>
                    <div class="col-xs-8">Gave a lecture <a
                            href="https://docs.google.com/presentation/d/1GcEasSFvCeofLrdZsFCwa3uLc2IBMmTAhTNgCvHmRx8/edit?usp=sharing">"On
                            what's possible today?"</a> in Dr. Parikh's <a
                            href="https://samyak-268.github.io/F19CS6476/">Computer Vision
                            course</a>
                    </div>
                </div>
                <div class="row">
                    <div class="col-xs-4 news-date">Nov 2019</div>
                    <div class="col-xs-8">Gave a lecture on <a
                            href="https://www.cc.gatech.edu/classes/AY2020/cs7643_fall/slides/L26_meta_learning.pdf">"Meta
                            Learning"</a> in Dr. Batra's <a
                            href="https://www.cc.gatech.edu/classes/AY2020/cs7643_fall/">Deep Learning course</a>.</div>
                </div>
                <div class="row">
                    <div class="col-xs-4 news-date">Jul 2019</div>
                    <div class="col-xs-8">Two papers accepted in ICCV 2019!</div>
                </div>
                <div class="row">
                    <div class="col-xs-4 news-date">Jun 2019</div>
                    <div class="col-xs-8">We were runner-up in the <a href="https://textvqa.org/">TextVQA</a> Challenge
                        2019. </div>
                </div>
                <div class="row">
                    <div class="col-xs-4 news-date">Apr 2019</div>
                    <div class="col-xs-8">Received the College of Computing CS7001 Research Award.</div>
                </div>
                <div class="row">
                    <div class="col-xs-4 news-date">Feb 2019</div>
                    <div class="col-xs-8">CloudCV selected as a mentoring organization for <a
                            href="https://summerofcode.withgoogle.com/organizations/5709446018236416/"> Google Summer of
                            Code </a> 5th year in a row!</div>
                </div>
                <div class="row">
                    <div class="col-xs-4 news-date">Jan 2019</div>
                    <div class="col-xs-8">Received the <a href="https://snapresearchfs.splashthat.com"> Snap Fellowship!</a>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- About Section -->
    <section class="success" id="about">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Publications</h2>
                    <hr class="light">
                </div>
            </div>
            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <img class="img-responsive" src="img/soat.png" style="width: 300px;" alt="">
                </div>
                <div class="col-sm-8 col-xs-12">
                    <div class="pubt">SOAT: A Scene- and Object-Aware Transformer for Vision-and-Language Navigation</div>
                    <div class="puba">Abhinav Moudgil, Arjun Majumdar, <b>Harsh Agrawal</b>, Stefan Lee, Dhruv Batra</div>
                    <div class="pubv">Neural Information Processing Systems (NeurIPS) 2021 </div>
                    <div class="publ">
                        <ul>
                            <li>Coming Soon</li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <img class="img-responsive" src="img/uai2021_teaser.png" style="width: 300px;" alt="">
                </div>
                <div class="col-sm-8 col-xs-12">
                    <div class="pubt">Known unknowns: Learning novel concepts using reasoning-by-elimination</div>
                    <div class="puba"><b>Harsh Agrawal</b>, Eli A. Meirom, Yuval Atzmon, Shie Mannor, Gal Chechik</div>
                    <div class="pubv">Uncertainty in Artificial Intelligence (UAI) 2021 <b>(Long Talk)</b></div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://proceedings.mlr.press/v161/agrawal21a/agrawal21a.pdf">PDF</a></li>
                            <li><a href="https://drive.google.com/file/d/1aqM2XWzicxCGEe6BbVHKozkmdvvUd2kp/view?usp=sharing">Talk</a></li>
                            
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <img class="img-responsive" src="img/pointnav_teaser.png" style="width: 300px;" alt="">
                </div>
                <div class="col-sm-8 col-xs-12">
                    <div class="pubt">The Surprising Effectiveness of Visual Odometry Techniques
                        for Embodied PointGoal Navigation</div>
                    <div class="puba">Xiaoming Zhao, <b>Harsh Agrawal</b>, Dhruv Batra, Alex Schwing</div>
                    <div class="pubv">International Conference on Computer Vision (ICCV) 2021</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://arxiv.org/abs/2108.11550">PDF</a></li>
                            <li><a href="https://xiaoming-zhao.github.io/projects/pointnav-vo/">Project Page</a></li>
                            <li><a href="https://github.com/Xiaoming-Zhao/PointNav-VO">Code</a></li>
                        </ul>
                    </div> 
                </div>
            </div>
            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <img class="img-responsive" src="img/concat-vqa-large.png" style="width: 300px;" alt="">
                </div>
                <div class="col-sm-8 col-xs-12">
                    <div class="pubt">Contrast and Classify: Alternate Training for Robust VQA</div>
                    <div class="puba">Yash Kant, Abhinav Moudgil, Dhruv Batra, Devi Parikh, <b>Harsh Agrawal</b></div>
                    <div class="pubv">International Conference on Computer Vision (ICCV) 2021</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://arxiv.org/abs/2010.06087">PDF</a></li>
                            <li><a href="https://yashkant.github.io/projects/concat-vqa.html">Project Page</a></li>
                            <li><a href="https://github.com/yashkant/concat-vqa">Code</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <img class="img-responsive" src="img/textvqa.png" style="width: 400px;" alt="">
                </div>
                <div class="col-sm-8 col-xs-12">
                    <div class="pubt">Spatially Aware Multimodal Transformers for TextVQA</div>
                    <div class="puba">Yash Kant, Dhruv Batra, Peter Anderson, Alexander Schwing, Devi Parikh, Jiasen Lu,
                        <b>Harsh Agrawal</b></div>
                    <div class="pubv">European Conference on Computer Vision (ECCV) 2020</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://arxiv.org/abs/2007.12146">PDF</a></li>
                            <li><a href="https://github.com/yashkant/sam-textvqa">Code</a></li>
                            <li><a href="https://www.youtube.com/watch?v=uPZra6HfLd0">Short Talk</a></li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <img class="img-responsive" src="img/seq_cvae.png" style="width: 400px;" alt="">
                </div>
                <div class="col-sm-8 col-xs-12">
                    <div class="pubt">Sequential Latent Spaces for Modeling the Intention During Diverse Image
                        Captioning</div>
                    <div class="puba">Jyoti Aneja<sup>*</sup>, <b>Harsh Agrawal</b><sup>*</sup>, Dhruv Batra, Alexander Schwing
                    </div>
                    <div class="pubv">International Conference on Computer Vision (ICCV) 2019</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://arxiv.org/abs/1908.08529">PDF</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <img class="img-responsive" src="img/nocaps_teaser.jpg" style="width: 400px;" alt="">
                </div>
                <div class="col-sm-8 col-xs-12">
                    <div class="pubt">nocaps: novel object captioning at scale</div>
                    <div class="puba"><b>Harsh Agrawal</b><sup>*</sup>, Karan Desai<sup>*</sup>, Yufei Wang, Xinlei Chen,
                        Rishabh Jain, Mark Johnson, Dhruv Batra, Devi Parikh, Stefan Lee, Peter Anderson</div>
                    <div class="pubv">International Conference on Computer Vision (ICCV) 2019</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://arxiv.org/abs/1812.08658">PDF</a></li>
                            <li><a href="https://nocaps.org">Project Page</a></li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <img class="img-responsive" src="img/sortstory.png" style="width: 400px;" alt="">
                </div>
                <div class="col-sm-8 col-xs-12">
                    <div class="pubt">Sort Story: Sorting Jumbled Images and Captions into Stories</div>
                    <div class="puba"><b>Harsh Agrawal</b><sup>*</sup>, Arjun Chandrasekaran<sup>*</sup>, Dhruv Batra, Devi
                        Parikh, Mohit Bansal</div>
                    <div class="pubv">Empirical Methods in Natural Language Processing (EMNLP) 2016</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://arxiv.org/abs/1606.07493">PDF</a></li>
                            <li><a href="https://www.youtube.com/watch?v=CMRy4Y-ZwGE">AI Guild Podcast #2</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <img class="img-responsive" src="img/vqahat.png" style="width: 400px;" alt="">
                </div>
                <div class="col-sm-8 col-xs-12">
                    <div class="pubt">Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at
                        the Same Regions?</div>
                    <div class="puba">Abhishek Das<sup>*</sup>, <b>Harsh Agrawal</b><sup>*</sup>, C. Lawrence Zitnick, Devi
                        Parikh, Dhruv Batra</div>
                    <div class="pubv"> Computer Vision and Image Understanding (CVIU) 2017
                        <br> Emperical Methods in Natural Language Processing (EMNLP) 2016
                        <br> ICML 2016 Workshop on Visualization for Deep Learning (<b>Best Student Paper</b>)</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://arxiv.org/abs/1606.03556">PDF</a></li>
                            <li><a
                                    href="https://www.theverge.com/2016/7/12/12158238/first-click-deep-learning-algorithmic-black-boxes">The
                                    Verge</a></li>
                            <li><a
                                    href="https://nautil.us/issue/40/learning/is-artificial-intelligence-permanently-inscrutable">Nautilus</a>
                            </li>
                            <li><a
                                    href="https://www.newscientist.com/article/2095616-robot-eyes-and-humans-fix-on-different-things-to-decode-a-scene/">New
                                    Scientist</a></li>
                            <li><a
                                    href="https://www.technologyreview.com/s/601819/ai-is-learning-to-see-the-world-but-not-the-way-humans-do/">TechRadar</a>
                            </li>
                            <li><a
                                    href="https://www.techradar.com/news/world-of-tech/robots-and-humans-see-the-world-differently-but-we-don-t-know-why-1324165">MIT
                                    Tech Review</a></li>

                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <img class="img-responsive" src="img/objectproposals.png" style="width: 400px;">
                </div>
                <div class="col-sm-8 col-xs-12">
                    <div class="pubt">Object-Proposal Evaluation Protocol is 'Gameable'</div>
                    <div class="puba">Neelima Chavali<sup>*</sup>, <b>Harsh Agrawal</b><sup>*</sup>, Aroma
                        Mahendru<sup>*</sup>, Dhruv Batra</div>
                    <div class="pubv">Conference on Computer Vision and Patter Recognition (CVPR) 2016
                        (<b>Spotlight</b>)</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://filebox.ece.vt.edu/~aroma/web/object-proposals.html">Project</a></li>
                            <li><a href="https://arxiv.org/abs/1505.05836">PDF</a></li>
                            <li><a href="https://github.com/Cloud-CV/object-proposals">Github</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <img class="img-responsive" src="img/cloudcv_teaser.png" style="width: 400px;" alt="">
                </div>
                <div class="col-sm-8 col-xs-12">
                    <div class="pubt">CloudCV: Large Scale Distributed Computer Vision as a Cloud Service</div>
                    <div class="puba"><b>Harsh Agrawal</b>, Clint Solomon Mathialagan, Yash Goyal, Neelima Chavali, Prakriti
                        Banik, Akrit Mohapatra, Ahmed Osman, Dhruv Batra</div>
                    <div class="pubv">Book Chapter: Mobile Cloud Visual Media Computing, 265-290</div>
                    <div class="publ">
                        <ul>
                            <li><a href="http://cloudcv.org">Project</a></li>
                            <li><a href="https://arxiv.org/abs/1506.04130">PDF</a></li>
                            <li><a href="https://github.com/Cloud-CV">Github</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <img class="img-responsive" src="img/evalai_teaser.png" style="width: 300px;" alt="">
                </div>
                <div class="col-sm-8 col-xs-12">
                    <div class="pubt">EvalAI: Towards Better Evaluation Systems for AI Agents</div>
                    <div class="puba">Deshraj Yadav, Rishabh Jain, <b>Harsh Agrawal</b>, Prithvijit Chattopadhyay, Taranjeet
                        Singh, Akash Jain, Shiv Baran Singh, Stefan Lee, Dhruv Batra</div>
                    <div class="pubv">AI Systems Workshop (SOSP 2019)</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://arxiv.org/abs/1902.03570">PDF</a></li>
                            <li><a href="https://evalai.cloudcv.org">Project Page</a></li>
                            <li><a href="https://github.com/Cloud-CV/EvalAI">Github</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-4 col-xs-12">
                    <img class="img-responsive" src="img/fabrik_teaser.png" style="width: 400px;" alt="">
                </div>
                <div class="col-sm-8 col-xs-12">
                    <div class="pubt">Fabrik: An Online Collaborative Neural Network Editor</div>
                    <div class="puba">Utsav Garg, Viraj Prabhu, Deshraj Yadav, Ram Ramrakhya, <b>Harsh Agrawal</b>, Dhruv Batra
                    </div>
                    <div class="pubv">AI Systems Workshop (SOSP 2019)</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://arxiv.org/abs/1810.11649">PDF</a></li>
                            <li><a href="https://fabrik.cloudcv.org">Project Page</a></li>
                            <li><a href="https://github.com/Cloud-CV/Fabrik">Github</a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section>
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Talks</h2>
                    <hr class="light">
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12 text-center">
                <div class="pubt">Known unknowns: Learning novel concepts using reasoning-by-elimination (UAI Oral Talk)</div>
                <br>
                <iframe src="https://drive.google.com/file/d/1aqM2XWzicxCGEe6BbVHKozkmdvvUd2kp/preview"
                    width="480" height="320" allowfullscreen></iframe>
                    
                </div>

            </div>

        </div>
    </section>


    <!-- Portfolio Grid Section -->
    <section id="projects">
        <div class="">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Projects</h2>
                    <hr class="light">
                </div>
            </div>
            <div class="band">
                <div class="item-1">
                    <a href="#EvalAI" class="card portfolio-link" data-toggle="modal">
                        <div class="thumb"
                            style="width: 400px; background-image: url(https://raw.githubusercontent.com/Cloud-CV/EvalAI/master/docs/source/_static/img/evalai_logo.png);">
                        </div>
                        <article class="article">
                            <h1>EvalAI</h1>
                            <p>An open source platform to create, collaborate and participate in the AI Challenges. By
                                simplifying and standardizing the process of
                                benchmarking AI, we want to circumvent many of the factors impeding the rate of progress
                                in AI.</p>
                            <span>Georgia Tech</span>
                        </article>
                    </a>
                </div>
                <div class="item-2">
                    <a href="#Fabrik" class="card portfolio-link">
                        <div class="thumb" style="background-image: url(img/Fabrik.png);"></div>
                        <article class="article">
                            <h1>Fabrik</h1>
                            <p>An online collaborative platform to build, visualize and train deep learning models via a
                                simple drag-and-drop interface.</p>
                            <span>Georgia Tech</span>
                        </article>
                    </a>
                </div>
                <div class="item-3">
                    <a href="#Origami" class="card portfolio-link" data-toggle="modal">
                        <div class="thumb" style="background-image: url(img/Origami.jpg);"></div>
                        <article class="article">
                            <h1>Origami</h1>
                            <p>A tool to allow researchers to automagically convert their deep learning models into an
                                online service in a few simple steps.</p>
                            </p>
                            <span>Georgia Tech</span>
                        </article>
                    </a>
                </div>
                <div class="item-4">
                    <a href="#CloudCV" class="card portfolio-link" data-toggle="modal">
                        <div class="thumb" style="background-image: url(img/cloudcv.png);"></div>
                        <article class="article">
                            <h1>CloudCV</h1>
                            <p>A collection of open-source platforms that aims to make research more reproducible.</p>
                            <span>Georgia Tech</span>
                        </article>
                    </a>
                </div>
                <div class="item-5">
                    <a href="#Garuda" class="card portfolio-link" data-toggle="modal">
                        <div class="thumb" style="background-image: url(img/garuda.jpg)"></div>
                        <article class="article">
                            <h1>Garuda</h1>
                            <p>An Unmanned Aerial Vehicle capable of
                                performing autonomous flight & surveillance.</p>
                            <span>UAS-DTU</span>
                        </article>
                    </a>
                </div>
                <div class="item-6">
                    <a href="#Aarush" class="card portfolio-link" data-toggle="modal">
                        <div class="thumb" style="background-image: url(img/Arush_X1.JPG);"></div>
                        <article class="article">
                            <h1>Aarush X-1</h1>
                            <p>An indigenously developed UAV developed under the mentorship of Lockheed Martin </p>
                            <span>UAS-DTU</span>
                        </article>
                    </a>
                </div>
                <div class="item-7">
                    <a href="#AMTChat" class="card portfolio-link" data-toggle="modal">
                        <div class="thumb" style="background-image: url(img/amtchat.png);"></div>
                        <article class="article">
                            <h1>AMT Chat Interface</h1>
                            <p>Source for the two-person chat interface used to collect the VisDial dataset on Amazon
                                Mechanical Turk.</p>
                            <span>Virginia Tech</span>
                        </article>
                    </a>
                </div>
                <div class="item-8">
                    <a href="#NoteWorthy" class="card portfolio-link" data-toggle="modal">
                        <div class="thumb" style="background-image: url(img/noteworthy3.png);"></div>
                        <article class="article">
                            <h1>Noteworthy</h1>
                            <p>An AI powered note-taking app developed while participating in MHacks 2014. </p>
                            <span>M Hacks</span>
                        </article>
                    </a>
                </div>
                <div class="item-9">
                    <a href="#Mobishare" class="card portfolio-link" data-toggle="modal">
                        <div class="thumb" style="background-image: url(img/mobishare.png);"></div>
                        <article class="article">
                            <h1>Mobishare</h1>
                            <p>System designed to support opportunistic content search and sharing with limited 2G
                                connection.</p>
                            <span>IIIT-D</span>
                        </article>
                    </a>
                </div>

                <div class="item-10">
                    <a href="#Trippr" class="card portfolio-link" data-toggle="modal">
                        <div class="thumb" style="background-image: url(img/trippr.png);"></div>
                        <article class="article">
                            <h1>Trippr</h1>
                            <p>A collaborative trip planning app powered by IBM Watson based personal assistant.</p>
                            <span>AngelHacks 2015</span>
                        </article>
                    </a>
                </div>


            </div>
        </div>
    </section>


    <!-- Footer 
        <footer class="text-center">
            <div class="footer-below">
                <div class="container">
                    <div class="row">
                        <div class="col-lg-12">
                            Copyright &copy; Harsh Agrawal 2016
                        </div>
                    </div>
                </div>
            </div>
        </footer>
    -->

    <!-- Scroll to Top Button (Only visible on small and extra-small screen sizes) -->
    <div class="scroll-top page-scroll visible-xs visible-sm">
        <a class="btn btn-primary" href="#page-top">
            <i class="fa fa-chevron-up"></i>
        </a>
    </div>

    <!-- Portfolio Modals -->
    <div class="portfolio-modal modal fade" id="CloudCV" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-xs-12">
                        <div class="modal-body">
                            <h2>CloudCV</h2>
                            <br>
                            <img src="img/cloudcv_banner.png" class="img-responsive img-centered" alt="">

                            <p> CloudCV began in the summer of 2013 as a research project within the Machine Learning
                                and Perception lab at Virginia Tech (now at Georgia Tech), with the ambitious goal of
                                making platforms to make AI research more reproducible. We’re a young community working
                                towards enabling developers, researchers, and fellow students to build, compare and
                                share state-of-the-art Artificial Intelligence algorithms. We believe that one shouldn’t
                                have to be an AI expert to have access to cutting edge vision algorithms. Likewise,
                                researchers shouldn’t have to worry about building a service around their deep learning
                                models to showcase and share it with others. </p>

                            <p> We have participated in the past three installments of Google Summer of Code
                                (2015-2017), over the course of which our students built several excellent tools and
                                features.
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="http://cloudcv.org">Website</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://github.com/Cloud-CV">Github</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a
                                            href="https://summerofcode.withgoogle.com/organizations/5746858777378816/">GSOC</a>
                                    </strong>
                                </li>
                            </ul>

                            <div class="row">
                                <div class="col-xs-6">
                                    <h3> Python APIs in action</h3>
                                    <img class="img-responsive"
                                        src="https://raw.githubusercontent.com/Cloud-CV/py-cloudcv/b3bb1a362fbd2f3a250419a078d3987db90ff0d7/python_screenshot.gif">
                                </div>
                                <div class="col-xs-6">
                                    <h3> Matlab APIs in action</h3>
                                    <img class="img-responsive"
                                        src="https://raw.githubusercontent.com/Cloud-CV/mat-cloudcv/master/matlab_screenshot.gif">

                                </div>
                            </div>

                            <button type="button" class="btn btn-default" data-dismiss="modal"><i
                                    class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Aarush" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Aarush X-1</h2>
                            <br>
                            <img src="img/Arush_X1.JPG" class="img-responsive img-centered" alt="">
                            <p>Aarush is a prototype of the UAV developed with financial resources and engineering
                                mentoring support
                                from Lockheed Martin Corporation. Traffic Management, Geomatics, Mining Surveillance,
                                Border patrol
                                are just some of the areas in which this UAV can be put to effective, efficient use.
                            </p>
                            <br>
                            <h3> Teaser Video </h3>
                            <br>
                            <iframe src="https://www.youtube.com/embed/BL-Rbf3iEKI" frameborder="0" allowfullscreen
                                style="position: relative; height: 750px; width: 100%;"></iframe>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i
                                    class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Origami" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Origami</h2>
                            <br>
                            <img src="img/origami_banner.png" class="img-responsive img-centered" alt="">
                            <p>Origami (previously called CloudCV-fy your code) is a AI-as-a-service solution that
                                allows researchers to easily convert their deep learning models into an online service
                                that is widely accessible to everyone without the need to setup the infrastructure,
                                resolve the dependencies, and build a web service around the deep learning model. By
                                lowering the barrier to entry to latest AI algorithms, we provide developers,
                                researchers and students the ability to access any model using a simple REST API call.
                            </p>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="http://origami.cloudcv.org">Website</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://github.com/Cloud-CV/Origami">Github</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://gitter.im/Cloud-CV/Origami">Gitter Channel</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i
                                    class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="EvalAI" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>EvalAI</h2>
                            <br>
                            <img src="img/evalai_logo.png" class="img-responsive img-centered" alt="">
                            <h3> The Problem: Benchmarking progress in AI is hard </h3>

                            <p>
                                Artificial Intelligence (AI) as a field has progressed significantly in the recent
                                years. A major portion of this progress can be attributed to the proposal of bold new
                                multi-modal AI tasks (recognition, captioning, VQA, Visual Dialog) together with
                                curation of associated datasets -- Common Objects in COntext (COCO), ImageNet, Visual
                                Question Answering (VQA), Stanford Question Answering Dataset (SQUAD), etc. Moving
                                forward, with more datasets being released and new tasks being proposed, comparing a new
                                algorithm with existing algorithms is nontrivial and is hindered by multiple factors:

                            <ol class="list item-details">
                                <li>Different evaluation schemes for the same task.</li>
                                <li>Implementation of the different metric or evaluation across different splits of the
                                    dataset.</li>
                                <li>Computational bottlenecks on evaluation servers holding unseen test data.</li>
                            </ol>
                            </p>

                            <h3>The Solution: EvalAI</h3>
                            <p>
                                EvalAI is an open source web platform that aims to help researchers, students and data
                                scientists create, collaborate, and participate in AI challenges. By simplifying and
                                standardizing the process of benchmarking AI, we want to circumvent many of the factors
                                impeding the rate of progress in AI. Our plan is to do this in the following ways:

                            <ol class="list item-details">
                                <li>Reduced barrier to entry for hosting AI challenges.</li>
                                <li>Standardized evaluation protocols (same dataset splits and metrics) for measuring
                                    the performance of different algorithms on a given task.<br></li>
                                <li>Central public leaderboards (“who is the best on X?”).</li>
                                <li>Faster evaluation of submissions using parallelization techniques that take
                                    advantage of distributed multi-core machines.</li>
                            </ol>
                            </p>

                            <h3> Important links: </h3>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="https://evalai.cloudcv.org">Website</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://github.com/Cloud-CV/EvalAI">Github</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://evalai.readthedocs.io/en/latest/">Documentation</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://gitter.im/Cloud-CV/EvalAI">Gitter Link</a>
                                    </strong>
                                </li>
                            </ul>

                            <h3> How it is different from Kaggle? </h3>
                            <p>
                                The central differences are:

                            <ul class="list item-details">
                                <li> Custom Evaluation Protocols and Phases: We have designed versatile backend
                                    framework that can support user-defined evaluation metrics, various evaluation
                                    phases, private and public leaderboard. </li>
                                <li> Faster Evaluation: The backend evaluation pipeline is engineered so that
                                    submissions can be evaluated parallelly using multiple cores on multiple machines
                                    via mapreduce frameworks offering a significant performance boost over similar web
                                    AI-challenge platforms.</li>
                                <li>Portability: Since the platform is open-source, users have the freedom to host
                                    challenges on their own private servers rather than having to explicitly depend on
                                    Cloud Services such as AWS, Azure, etc.</li>
                                <li>Centralized Leaderboard: Challenge Organizers whether host their challenge on EvalAI
                                    or forked version of EvalAI, they can send the results to main EvalAI server. This
                                    helps to build a centralized platform to keep track of different challenges.</li>

                            </ul>
                            </p>


                            <h3> Performance comparisons with other platforms: </h3>

                            <p> EvalAI hosted Visual Question Answering (VQA) 2017 challenge as its first challenge. To
                                give some background, last year, the VQA 2016 challenge was hosted on Codalab, and on
                                average evaluation would take ~10 minutes. This year, the dataset for the VQA Challenge
                                2017 was twice as large. Despite this, we have found that our parallelized backend took
                                only ~130 seconds to evaluate on the whole test set of VQA dataset. </p>

                            <h3> Research Organizations using EvalAI: </h3>

                            <div class="row">
                                <div class="col-xs-3"><img
                                        src="https://evalai.cloudcv.org/dist/images/organizations/fb.png"
                                        class="img-responsive img-centered" alt=""></div>
                                <div class="col-xs-3"><img
                                        src="https://evalai.cloudcv.org/dist/images/organizations/google.png"
                                        class="img-responsive img-centered" alt=""></div>
                                <div class="col-xs-3"><img
                                        src="https://evalai.cloudcv.org/dist/images/organizations/mapillary.png"
                                        class="img-responsive img-centered" alt=""></div>
                                <div class="col-xs-3"><img
                                        src="https://evalai.cloudcv.org/dist/images/organizations/gt.png"
                                        class="img-responsive img-centered" alt=""></div>
                            </div>

                            <br>
                            <br>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i
                                    class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Fabrik" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Fabrik</h2>
                            <br>
                            <img src="https://github.com/Cloud-CV/Fabrik/raw/master/example/fabrik_demo.gif?raw=true"
                                class="img-responsive img-centered" alt="">
                            <p> Fabrik is an online collaborative platform to build, visualize and train deep learning
                                models via a simple drag-and-drop interface. It allows researchers to collaboratively
                                develop and debug models using a web GUI that supports importing, editing and exporting
                                networks written in widely popular frameworks like Caffe, Keras, and TensorFlow.</p>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="http://fabrik.cloudcv.org">Website</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://github.com/Cloud-CV/Fabrik">Github</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://gitter.im/Cloud-CV/IDE">Gitter Channel</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i
                                    class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Garuda" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Garuda</h2>
                            <br>
                            <img src="img/garuda.jpg" class="img-responsive img-centered" alt="">
                            <p>GARUDA, a modified Sig Rascal 110 R/C aircraft along with its Ground Control System is
                                capable of performing
                                autonomous flight & navigation, simultaneously gathering actionable surveillance data
                                using optical sensors.
                                The system includes commercially available autopilot system, Piccolo II for control &
                                navigation with a customized
                                imagery system capable of capturing & transmitting high definition images of the hostile
                                territory simultaneously
                                processing it to deliver actionable intelligence. The Ground Control Station (GCS) and
                                the aircraft communicate
                                in real time to provide situational awareness and safe and reliable flight. Due to it's
                                modular design, the entire system
                                can be brought to a flying state in less than 20 minutes. We participated with this
                                system in Student Unmanned Aerial Systems (SUAS) 2012 competition and secured 3rd
                                position.</p>

                            <p> Garuda was developed as part of the Unmanned Aerial Systems - Delhi Technological
                                University (UAS-DTU) project. UAS-DTU is a team of undergraduate students of Delhi
                                Technological University, devoted to developing indigenous technological solutions for
                                UAVs. Our ultimate goal was to reduce India's reliance on off-the-shelf products and
                                foreign UAVs. Focussing on humanitarian uses of UAVs, we are developing a new generation
                                of low-cost Image Processing and Flight Control Systems to aid in Surveillance and
                                Reconnaissance.</p>

                            <p>The team, under mentorship and funding from Lockheed Martin, is the first to develop a
                                Next Generation Urban UAS - Aarush X1, that is tailor- made for surveillance in urban
                                jungles like Delhi and Mumbai. The team signed its first MoU with Lockheed Martin in
                                2009. The second MoU was signed in 2013, under which a new version of Aarush (Aarush X2)
                                is being developed. The team annually participates in AUVSIs SUAS competition, which
                                stands for Student Unmanned Aerial Systems competition. The competition is held in
                                Maryland, USA where more than 30 universities come every year with their UAVs hoping to
                                win the competition. We are the first team from India to participate in this competition
                                (Our first participation was in 2009), and also the first team from India to achieve a
                                podium finish (We were ranked 3rd in 2012). In 2013, the team ranked 6th. After these
                                years of experience through the competition and Lockheed Martin project, we are now
                                capable of manufacturing Unmanned Aerial Systems for the market with the capabilities of
                                Aerial Imagery, and GCS Softwares for the processing of these images.</p>
                            <br>
                            <h3>Video: Journey of UAS-DTU</h3>
                            <br>
                            <iframe src="https://www.facebook.com/video/embed?video_id=10151167933007739" width="560"
                                height="315" style="border:none;overflow:hidden" scrolling="no" frameborder="0"
                                allowTransparency="true" allowFullScreen="true"></iframe>
                            <br>
                            <h3>Important Links</h3>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="img/journal_2012.pdf">Journal Paper</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a
                                            href="http://www.thehindu.com/todays-paper/tp-features/tp-educationplus/laurels-for-team-uasdtu/article3796999.ece">Article
                                            in The Hindu</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i
                                    class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="AMTChat" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>AMT Chat Interface</h2>
                            <br>
                            <img src="img/amtchat.png" class="img-responsive img-centered" alt="">
                            <p>Source for the two-person chat interface used to collect the VisDial dataset on Amazon
                                Mechanical Turk. A demo is available <href src="https://godel.ece.vt.edu/visdial_chat/">
                                    here</href> (open in two separate tabs to be paired for conversation).</p>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="https://github.com/batra-mlp-lab/visdial-amt-chat">Github</a>
                                    </strong>
                                </li>

                            </ul>
                            <h3> How things works </h3>
                            <p>
                                The real-time chat interface is built using Node.js and Socket.io. We use Redis to
                                maintain a pool of images for live HITs and all data finally resides in a MySQL
                                database.
                                <br><br>
                                A database table stores images from the COCO dataset each with a randomly picked
                                caption. A batch of images from this table are then pushed to a Redis list for launching
                                HITs. The web server corresponding to the chat interface pairs two AMT workers, assigns
                                them roles (questioner or answerer) and shows corresponding interface, picks an image
                                from the Redis list to collect data on and saves their conversation in the database,
                                also marking that image as 'complete' once the HIT is done. This happens in parallel so
                                workers aren't left waiting, and the server ensures workers have unique ids. Disconnects
                                are handled gracefully — remaining worker is asked to continue asking questions or
                                providing facts (captions) up to 10 messages. Once the HITs are complete, scripts in
                                mturk_scripts/approve can be used to review, approve, reject HITs and pay workers.

                            </p>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i
                                    class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="NoteWorthy" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>NoteWorthy</h2>
                            <br>
                            <div class="row">
                                <div class="col-xs-3 col-md-3">
                                    <img src="img/noteworthy1.png" class="img-responsive img-centered" alt=""></div>
                                <div class="col-xs-3 col-md-3">
                                    <img src="img/noteworthy2.png" class="img-responsive img-centered" alt=""></div>
                                <div class="col-xs-3 col-md-3">
                                    <img src="img/noteworthy3.png" class="img-responsive img-centered" alt=""></div>
                                <div class="col-xs-3 col-md-3">
                                    <img src="img/noteworthy4.png" class="img-responsive img-centered" alt=""></div>
                            </div>
                            <div class="row">
                                <p>What if you could replace the slow and monotone professor with complete and efficient
                                    notes? Rather than begging for them from the smartest students in class, Noteworthy
                                    provides a smart alternative ecosystem of notes. Whether you've simply wanted to
                                    skip a class without the academic problems, or you wanted to reinforce your
                                    education, Noteworthy gives you the greatest studying experience. Noteworthy, an app
                                    founded at MHacks, allows for easy and seamless digitization of notes. Noteworthy
                                    takes the noteworthiest notes from across the world, and brings them to you
                                    anywhere. With course, professor, and date choices, students can find the right
                                    notes for the right class on the right day. Noteworthy will save you time and get
                                    you better results for your education.</p>

                                <p>Noteworthy was developed while participating in MHacks 2014 - one of the biggest 48
                                    hour hackathon competition orgamized by University of Michigan, Ann Arbor</p>
                            </div>


                            <button type="button" class="btn btn-default" data-dismiss="modal"><i
                                    class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Trippr" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>Trippr</h2>
                            <br>

                            <p> Trippr is a collaborative trip planning app powered by IBM Watson based personal
                                assistant. This app was developed while participating
                                in Angel Hacks, Seattle - a 24 hour hackathon in the summer of 2013. It consisted of a
                                combination of Android app, Pebble Smartwatch app and a Web app through which
                                people can chat online with their friends, ask questions to a smart personal assistant
                                and book iteneraries. </p>

                            <p> The personal assistant powered by IBM Watson can hold conversation with the group of
                                users to suggest popular destinations, restaurants, cheapest flights. It also
                                automatically built an itenerary based on users choices. This app provided smart
                                features similar to Google Trips.</p>

                            <p> Our app also won the "Best use of Respoke API" award.</p>

                            <button type="button" class="btn btn-default" data-dismiss="modal"><i
                                    class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Mobishare" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Mobishare</h2>
                            <br>
                            <img src="img/MSR_TechV2013.jpg" class="img-responsive img-centered" alt="">
                            <p>

                            </p>

                            <button type="button" class="btn btn-default" data-dismiss="modal"><i
                                    class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="js/classie.js"></script>
    <script src="js/cbpAnimatedHeader.js"></script>

    <script src="js/timeline.js"></script>
    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/freelancer.js"></script>
    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date(); a = s.createElement(o),
                m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-92670333-1', 'auto');
        ga('require', 'ipMeta', {
            serviceProvider: 'dimension1',
            networkDomain: 'dimension2',
            networkType: 'dimension3',
        });
        ga('ipMeta:loadNetworkFields');
        ga('send', 'pageview');
    </script>
    <script async src="https://ipmeta.io/plugin.js"></script>
</body>

</html>
